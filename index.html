<!DOCTYPE html>



<html>

<head>
  <meta name="msvalidate.01" content="4953F173B09D5FE6EF14ADE0D0A976AE" />
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="MMSQL">
  <meta property="og:title" content="MMSQL" />
  <meta property="og:description" content="MMSQL" />
  <meta property="og:url" content="https://mcxiaoxiao.github.io/MMSQL/" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/logo.png" />
  <meta property="og:image:width" content="630" />
  <meta property="og:image:height" content="630" />
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <!-- <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1"> -->


  <title>MMSQL | Evaluating and Enhancing LLMs for Multi-turn Text-to-SQL with Multiple Question Types</title>
  <link rel="icon" type="image/x-icon" href="static/images/logo.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Evaluating and Enhancing LLMs for Multi-turn Text-to-SQL with
              Multiple Question Types</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://mcxiaoxiao.github.io" target="_blank">Ziming Guo</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="https://faculty.hrbust.edu.cn/jsj/mc/main.htm" target="_blank">Chao Ma</a>,</span>
              <span class="author-block">
                <a href="https://github.com/sunyinggang" target="_blank">Yinggang Sun</a>,</span>
              <span class="author-block">
                <a href="https://github.com/AKA-Tian7" target="_blank">Tiancheng Zhao</a>,</span>
              <span class="author-block">
                <a href="https://github.com/GoldGhastTears" target="_blank">Guangyao Wang</a>,</span>
              <span class="author-block">
                <a href="https://faculty.hrbust.edu.cn/jsj/hh/main.htm" target="_blank">Hai Huang</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Harbin University of Science and Technology, Harbin Institute of
                Technology<br>UnderReview 2024</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Any questions? ðŸ“« orlosziming@outlook.com</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2412.17867" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Supplementary PDF link -->
                <span class="link-block">
                  <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/mcxiaoxiao/MMSQL" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2412.17867" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2412.17867" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-zhihu"></i>
                    </span>
                    <span>Zhihu</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="#datasets" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-table"></i>
                    </span>
                    <span>Datasets</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Teaser video-->
  <!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
  <!-- End teaser video -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Recent advancements in large language models (LLMs) have boosted text-to-SQL systems, but many miss the
              mark on handling real-world conversations. This can lead to issues with tricky questions that SQL alone
              can't solve. To tackle this, we created MMSQL, a test suite that checks how well LLMs handle different
              question types and multi-turn chats. We tested popular LLMs and found what affects their performance.
              Plus, we developed a multi-agent system to better identify question types and choose the right strategies.
              Our experiments show this enhances modelâ€™s ability to  navigate the complexities of conversational dynamics.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->



  <section class="hero is-small">
    <div class="hero-body">
      
      
      <div class="container is-max-desktop content">
        <div class="content">
          <h2 class="title is-3">Motivation</h2>
          <img src="static/images/1.svg" alt="fig.1" class="center-image" />
      <p class="has-text-centered">
        Fig. 1 A four-turn dialogue example that includes four different types of Q&A pairs.
      </p>
          <p>
            In the realm of text-to-SQL systems, which empower non-technical users to query databases using natural
            language, the advent of large language models (LLMs) has led to significant advancements. However, a
            critical challenge remains: handling the dynamic and uncertain nature of real-world user queries. These
            queries often unfold over multiple turns and can be ambiguous or unanswerable. For instance, users may ask
            questions that lack the necessary data in the database or are open to multiple interpretations, as
            illustrated in Figure 1. Additionally, some queries may be entirely unrelated to the database content,
            requiring the system to discern when not to generate SQL responses. Current models frequently assume all
            queries are clear and answerable, a limitation that can lead to hallucinated content and unreliable
            predictions. Addressing these issues is essential for developing more robust and dependable text-to-SQL
            systems.
          </p>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">
      
      
      <div class="container is-max-desktop content">
        <div class="content">
          <h2 class="title is-3">Dataset</h2>
          <img src="static/images/2.png" alt="Table 1" class="center-image" style="max-width: 700px;" />
      <p class="has-text-centered">
        Table 1 Comparison of multi-turn or multi-type text-to-SQL datasets.
      </p>
          <p>
            We used <a href="https://github.com/mcxiaoxiao/QDA-SQL" target="_blank"> QDA-SQL </a> to generate a training
            set with 4 question types: "answerable", "unanswerable", "improper", "ambiguous". We manually annotated the
            test set, as shown in Table 1. Our MMSQL dataset, with its complex multi-turn and multi-type
            characteristics, reflects more realistic scenarios.
          </p>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">

      <div class="container is-max-desktop content">
        <div class="content">
          <img src="static/images/qda.svg" alt="fig.2" class="center-image" style="min-width: 700px;" />
          <p class="has-text-centered">
            Fig. 2 Overview of QDA-SQL processes. (Method of dataset construction)
          </p>
          <p>
            <a href="https://github.com/mcxiaoxiao/QDA-SQL" target="_blank"> QDA-SQL </a>(Questions Enhanced Dialogue
            Augmentation for Multi-turn Text-to-SQL) uses Chain of Thought (CoT) reasoning to generate multi-turn Q&A
            pairs step-by-step. It combines context relationships and question types randomly, followed by a refinement
            process, guiding Gemini Pro to create diverse datasets. This ensures each sample fits our defined question
            types. The samples produced by QDA-SQL showed higher natural language annotation quality, with a 62% win
            rate, and included more complex text-to-SQL examples compared to the original dataset.
          </p>
          <p>
            In our dataset generation process, we used samples from SPARC and CoSQL as GoalSQL as GoalSQL, transforming them into multi-turn, multi-type datasets in our format. You can preview or download the following datasets:
          </p>
          <table id="datasets">
            <thead>
              <tr>
                <th>Dataset</th>
                <th>Download Link</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>MMSQL Test Set (238 KB)</td>
                <td>
                  <a href="https://raw.githubusercontent.com/mcxiaoxiao/MMSQL/refs/heads/paper/datasets/MMSQL_test.json">Preview</a> |
                  <a href="static/datasets/MMSQL_test.json" download>Download</a>                </td>
              </tr>
              <tr>
                <td>MMSQL Training Set (16.5 MB)</td>
                <td>
                  <a href="https://raw.githubusercontent.com/mcxiaoxiao/MMSQL/refs/heads/paper/datasets/MMSQL_train.json">Preview</a> |
                  <a href="static/datasets/MMSQL_train.json" download>Download</a>                </td>
              </tr>
      
            </tbody>
          </table>
          <h2 class="title is-3">Evaluation</h2>
          <p>Our evaluation metrics include Exact Matching (EM) and Execution Accuracy (EX). EM compares each predicted clause to the reference query, considering it correct only if all components match, excluding values. EX evaluates the proportion of SQL where the execution results of both predicted and ground-truth SQL are identical. Interaction Execution Accuracy (IEX) is achieved when all SQL queries in a multi-turn interaction execute correctly. We also developed the Dual Assessment of Question Type Detection and Execution Accuracy (TDEX) to assess the comprehensive capability of text-to-SQL models with complex queries. Additionally, the Response Quality Score (RQS) measures the quality of the model's natural language responses.</p>

          <p>TDEX is a comprehensive metric that evaluates the accuracy of user query type classification and execution accuracy. For a set of \( N \) questions, where \( C_i \) denotes the expected classification and \( \hat{C}_i \) represents the predicted classification for the \( i \)-th question, \( S_i \) denotes the ground truth SQL query and \( \hat{S}_i \) represents the predicted SQL query for the \( i \)-th question, TDEX is computed as:</p>

          \[
          \text{TDEX} = \frac{1}{N} \sum_{i=1}^{N} \left\{
          \begin{array}{ll}
          \varepsilon_{\text{exec}}(S_i, \widehat{S}_i) & \text{(a)} \\
          \delta_{\text{type}}(C_i, \widehat{C}_i) & \text{(b)}\\
          \end{array}
          \right.
          \]
      
          \[
          \begin{array}{ll}
            \text{(a)} &  C_i = \mathrm{'Answerable' }  ~\text{or}~  \mathrm{ 'Ambiguous'} \\
            \text{(b)} & \mathrm{otherwise}
          \end{array}
          \]
      
          <p>where \( \varepsilon_{\text{exec}} = 1 \) if the execution result of \( \hat{S}_i \) matches the execution result of \( S_i \), and \( \varepsilon_{\text{exec}} = 0 \) otherwise; \( \delta_{\text{type}} = 1 \) if \( \hat{C}_i \) matches \( C_i \), and \( \delta_{\text{type}} = 0 \) otherwise.</p>
          <p>To evaluate the quality of a model's responses, we use an LLM-assisted rating method assessing Utility, Accuracy, Completeness, Clarity, and Relevance on a 0-to-2 scale, with a maximum score of 10.</p>
          <table>
            <thead>
            <tr>
                <th>Model</th>
                <th>TDEX</th>
                <th>IEX</th>
                <th>EX</th>
                <th>EM</th>
                <th>RQS</th>
            </tr>
          </thead>
            <tr>
                <td>GPT-4 Turbo</td>
                <td>67.0</td>
                <td>30.2</td>
                <td>70.0</td>
                <td>51.0</td>
                <td>5.80</td>
            </tr>
            <tr>
                <td>GPT-3.5 Turbo</td>
                <td>64.1</td>
                <td>25.5</td>
                <td>69.6</td>
                <td>47.3</td>
                <td>4.74</td>
            </tr>
            <tr>
                <td>Gemini-1.5 Flash</td>
                <td>65.8</td>
                <td>30.1</td>
                <td>70.0</td>
                <td>52.3</td>
                <td>4.03</td>
            </tr>
            <tr>
                <td>Llama3-70B</td>
                <td>62.8</td>
                <td>22.8</td>
                <td>66.4</td>
                <td>47.4</td>
                <td>3.86</td>
            </tr>
            <tr>
                <td>Llama3-8B</td>
                <td>64.0</td>
                <td>20.1</td>
                <td>66.1</td>
                <td>45.7</td>
                <td>4.55</td>
            </tr>
            <tr>
                <td>SQLCoder-8B</td>
                <td>30.7</td>
                <td>24.8</td>
                <td>63.2</td>
                <td>31.0</td>
                <td>3.43</td>
            </tr>
            <tr>
                <td>Codellama-7B</td>
                <td>30.7</td>
                <td>3.4</td>
                <td>27.2</td>
                <td>21.7</td>
                <td>5.09</td>
            </tr>
            <tr>
                <td>Mistral-7B-v0.2</td>
                <td>26.4</td>
                <td>0.7</td>
                <td>13.7</td>
                <td>11.2</td>
                <td>4.37</td>
            </tr>
        </table>
        <p class="has-text-centered">
          Table 2 Performance of the models on MMSQL test set.
        </p>
          As shown in table 2, we evaluated several Large Language Models (LLMs) on their zero-shot capabilities in handling multi-turn conversational text-to-SQL tasks using the MMSQL test set. Our main findings as below:</p>
          
            <ul>
              <li>Closed-source models currently have a slight performance edge, but open-source models are rapidly catching up, showing strong potential.<br>
                <li>All models struggle with unanswerable and ambiguous questions, marking areas that need significant improvement.<br>
                  <li>Incorporating clarification processes in multi-turn interactions allows models to formulate more precise SQL queries, enhancing the usability and effectiveness of text-to-SQL systems.</p>
        </ul>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">
      
      
      <div class="container is-max-desktop content">
        <div class="content">
          <h2 class="title is-3">Multi-Agent Framework</h2>
          <img src="static/images/multiagent.gif" alt="fig.2" class="center-image" style="max-width: 900px;" />
      <p class="has-text-centered">
        Fig. 2 The overview of our multi-agent framework comprises 4 components: (i) the Schema Selector, which narrows down the database schema to focus on relevant tables, reducing noise from irrelevant data; (ii) the Question Detector, which determines its type and reformulates it if the question is deemed potentially ambiguous, potentially generating multiple possible rewrites; (iii) the Question Decomposer, which breaks down complex questions into simpler, manageable sub-questions and applies chain-of-thought reasoning to solve them progressively; and (iv) the SQL Refiner, which utilizes an external tool for SQL execution, gathers feedback, then refines faulty SQL queries.
      </p>
          <p>
            We have developed a multi-agent collaborative framework designed to improve the performance of Large Language Models (LLMs) in text-to-SQL parsing tasks. This framework leverages intelligent agents with specialized functionalities, working together to enhance the accuracy and efficiency of converting natural language queries into SQL commands.
            <br>
Our framework consists of four key components:
<tr>
  <li>Schema Selector: This agent identifies the most relevant subset of the database schema needed to answer a given question, reducing noise and potential confusion caused by irrelevant data.</li>
<br>
<li>Question Detector: It determines the type of question and decides on the appropriate response strategy, effectively handling ambiguous or unanswerable queries by providing clarifications or alternative formulations.</li>
<br>
<li>Question Decomposer: This component breaks down complex questions into simpler, manageable sub-questions, applying chain-of-thought reasoning to progressively solve each part of the query.</li>
<br>
<li>SQL Refiner: It refines and verifies the SQL queries generated, utilizing external tools to execute the SQL statements, gather feedback, and iteratively correct any errors to ensure the accuracy of the final output.</li>
</tr></p>
          <img src="static/images/3.png" alt="Table 3" class="center-image"  style="max-width: 700px;" />
          <p class="has-text-centered">
            Table 3 Performance metrics comparison on the MMSQL test set, demonstrating the
            improvements achieved by integrating the multi-agent framework with different models. Specific
            improvements are indicated in parentheses.
          </p>
          <img src="static/images/4.png" alt="Table 4" class="center-image"  style="max-width: 600px;" />
          <p class="has-text-centered">
            Table 4 Ablation study examining the impact of each component within the
            multi-agent framework on the modelâ€™s performance on the MMSQL test set.            
          </p>
          <p>Our experiments demonstrate that integrating this multi-agent framework with existing LLMs significantly improves their performance in text-to-SQL tasks. By collaboratively employing specialized agents, our multi-agent framework enhances the capabilities of LLMs in handling complex, ambiguous, and multi-turn queries in text-to-SQL parsing. Each component contributes uniquely to the overall performance, ensuring that natural language queries are accurately and efficiently translated into SQL commands. This approach is particularly valuable in applications involving large, complex databases where precision and reliability are crucial.</p>
        </div>
      </div>
    </div>
  </section>




  <!-- Youtube video -->
  <!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
  <!-- End youtube video -->


  <!-- Video carousel -->
  <!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
  <!-- End video carousel -->






  <!-- Paper poster -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">Paper</h2>

        <iframe
          src="static/pdfs/Evaluating_and_Enhancing_LLMs_for_Multi-turn_Text-to-SQL_with _Multiple_Question_Types.pdf"
          width="100%" height="550">
        </iframe>

      </div>
    </div>
  </section>
  <!--End paper poster -->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{guo2024evaluatingenhancingllmsmultiturn,
        title={Evaluating and Enhancing LLMs for Multi-turn Text-to-SQL with Multiple Question Types}, 
        author={Ziming Guo and Chao Ma and Yinggang Sun and Tiancheng Zhao and Guangyao Wang and Hai Huang},
        year={2024},
        eprint={2412.17867},
        archivePrefix={arXiv},
        primaryClass={cs.CL},
        url={https://arxiv.org/abs/2412.17867}, 
  }</code></pre>
      <p>

        This work is licensed under <a href="https://creativecommons.org/licenses/by/4.0" target="_blank">CC BY 4.0</a>.
        You are free to use the code or dataset, please be sure to cite it in your paper or repository.
      </p>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <div class="footer-logos-container">
              <img src="static/images/logo.png" class="footer-logo" alt="Logo 1">
              <a href="https://www.hrbust.edu.cn" class="footer-logo" target="_blank">
                <img src="static/images/hust.png" alt="Harbin University of Science and Technology (HUST)">
              </a>
              <a href="https://www.hit.edu.cn" class="footer-logo" target="_blank" style="width: 7.1%;">
                <img src="static/images/hit.png" alt="Harbin Institute of Technology (HIT)">
              </a>
            </div>

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>