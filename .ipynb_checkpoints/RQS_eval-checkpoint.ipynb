{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687eb5bd-ce5f-4e1d-94cf-4df4aab4063a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                             | 0/148 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________\n",
      "0\n",
      "answerable -- How many students in the \"Student\" table are over the age of 20?\n",
      "Next Turn predict_sql: SELECT COUNT(*) FROM Student WHERE Age > 20\n",
      "Predict Type: answerable\n",
      "1\n",
      "answerable -- How many of those students own pets?\n",
      "Next Turn predict_sql: SELECT COUNT(DISTINCT S.StuID) FROM Student AS S JOIN Has_Pet AS HP ON S.StuID = HP.StuID WHERE S.Age > 20\n",
      "Predict Type: answerable\n",
      "__________________\n",
      "0\n",
      "answerable -- Can you list all the continents?\n",
      "Next Turn predict_sql: SELECT Continent FROM continents\n",
      "Predict Type: answerable\n",
      "1\n",
      "answerable -- Okay, now can you list the number of countries belonging to each continent, including the continent id as well?\n",
      "Next Turn predict_sql: SELECT c.ContId, c.Continent, COUNT(DISTINCT co.CountryId) AS NumberOfCountries FROM continents c JOIN countries co ON c.ContId = co.Continent GROUP BY c.ContId, c.Continent ORDER BY c.ContId\n",
      "Predict Type: answerable\n",
      "2\n",
      "improper -- Thanks!\n",
      "request gemini-1.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|███▌                                                                                                                                                                                                                                                                 | 2/148 [00:02<03:04,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSuccess: Operation completed after 0 retries\u001b[0m\n",
      "LLM Response: ```json\n",
      "{\n",
      "  \"AnswerType\": \"improper\",\n",
      "  \"Rationale\": \"The user's question is a simple greeting and does not require a database response. The system response is appropriate for a conversational context but irrelevant to the database information provided.\",\n",
      "  \"Score\": 2\n",
      "}\n",
      "``` \n",
      "\n",
      "formatted json {   \"AnswerType\": \"improper\",   \"Rationale\": \"The user's question is a simple greeting and does not require a database response. The system response is appropriate for a conversational context but irrelevant to the database information provided.\",   \"Score\": 2 }\n",
      "Next Turn predict_sql: \n",
      "Predict Type: improper\n",
      "__________________\n",
      "0\n",
      "unanswerable -- How many customers are there now?\n",
      "Next Turn predict_sql: SELECT COUNT(*) FROM visitor\n",
      "Predict Type: answerable\n",
      "1\n",
      "answerable -- How many visitors are ther?\n",
      "Next Turn predict_sql: SELECT COUNT(DISTINCT ID) FROM visitor\n",
      "Predict Type: answerable\n",
      "2\n",
      "answerable -- How many of them have membership levels higher than 4?\n",
      "Next Turn predict_sql: SELECT count(*) FROM visitor WHERE Level_of_membership > 4\n",
      "Predict Type: answerable\n",
      "3\n",
      "answerable -- Can you please list their names?\n",
      "Next Turn predict_sql: SELECT Name FROM visitor WHERE Level_of_membership  >  4  \n",
      "Predict Type: answerable\n",
      "4\n",
      "answerable -- Can you rank them by their membership level from high to low?\n",
      "Next Turn predict_sql: SELECT name, Level_of_membership FROM visitor ORDER BY Level_of_membership DESC\n",
      "Predict Type: answerable\n",
      "5\n",
      "improper -- Thanks!\n",
      "request gemini-1.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█████▎                                                                                                                                                                                                                                                               | 3/148 [00:05<04:33,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSuccess: Operation completed after 0 retries\u001b[0m\n",
      "LLM Response: ```json\n",
      "{\n",
      "  \"AnswerType\": \"improper\",\n",
      "  \"Rationale\": \"The user question is a simple greeting and does not require a database response. The system response is appropriate for a conversational context but irrelevant to the database task.  The system response is clear, complete, and accurate, but it is not useful in the context of a database interaction.\",\n",
      "  \"Score\": 6\n",
      "}\n",
      "``` \n",
      "\n",
      "formatted json {   \"AnswerType\": \"improper\",   \"Rationale\": \"The user question is a simple greeting and does not require a database response. The system response is appropriate for a conversational context but irrelevant to the database task.  The system response is clear, complete, and accurate, but it is not useful in the context of a database interaction.\",   \"Score\": 6 }\n",
      "Next Turn predict_sql: \n",
      "Predict Type: improper\n",
      "__________________\n",
      "0\n",
      "ambiguous -- Which cause has the least enrollment?\n",
      "Next Turn predict_sql: SELECT c.course_name FROM Courses c JOIN Student_Enrolment_Courses sec ON c.course_id = sec.course_id GROUP BY c.course_name ORDER BY COUNT(sec.student_course_id) ASC LIMIT 1\n",
      "Predict Type: answerable\n",
      "1\n",
      "answerable -- the name\n",
      "Next Turn predict_sql: SELECT T1.course_name FROM Courses AS T1 JOIN Student_Enrolment_Courses AS T2   ON T1.course_id = T2.course_id GROUP BY T1.course_name ORDER BY COUNT(T2.student_course_id) LIMIT 1\n",
      "Predict Type: answerable\n",
      "2\n",
      "answerable -- What is the course ID of Math?\n",
      "Next Turn predict_sql: SELECT course_id FROM Courses WHERE course_name = 'math'\n",
      "Predict Type: answerable\n",
      "3\n",
      "answerable -- How many students enrolled a course with the id of 14\n",
      "Next Turn predict_sql: SELECT COUNT(DISTINCT student_id) FROM Student_Enrolment_Courses WHERE course_id = 14\n",
      "Predict Type: answerable\n",
      "4\n",
      "improper -- Thanks!\n",
      "request gemini-1.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███████                                                                                                                                                                                                                                                              | 4/148 [00:07<05:13,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSuccess: Operation completed after 0 retries\u001b[0m\n",
      "LLM Response: ```json\n",
      "{\n",
      "  \"AnswerType\": \"improper\",\n",
      "  \"Rationale\": \"The user's question is a simple 'Thanks!' which is not a question related to SQL or database operations. The system response is a polite acknowledgement, which is appropriate but not relevant to the database context.\",\n",
      "  \"Score\": 10\n",
      "}\n",
      "``` \n",
      "\n",
      "formatted json {   \"AnswerType\": \"improper\",   \"Rationale\": \"The user's question is a simple 'Thanks!' which is not a question related to SQL or database operations. The system response is a polite acknowledgement, which is appropriate but not relevant to the database context.\",   \"Score\": 10 }\n",
      "Next Turn predict_sql: \n",
      "Predict Type: improper\n",
      "__________________\n",
      "0\n",
      "answerable -- Can you show the birth date of player id 200002?\n",
      "Next Turn predict_sql: SELECT birth_date FROM players WHERE player_id = 200002\n",
      "Predict Type: answerable\n",
      "1\n",
      "answerable -- What is the first name of player id 200001?\n",
      "Next Turn predict_sql: SELECT first_name FROM players WHERE player_id = 200001\n",
      "Predict Type: answerable\n",
      "2\n",
      "answerable -- Can you show the codes of countries that have more than 50 players?\n",
      "Next Turn predict_sql: SELECT country_code FROM players GROUP BY country_code HAVING COUNT(*) > 50 ```\n",
      "Predict Type: answerable\n",
      "3\n",
      "improper -- Thanks!\n",
      "request gemini-1.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████████▊                                                                                                                                                                                                                                                            | 5/148 [00:11<06:41,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSuccess: Operation completed after 0 retries\u001b[0m\n",
      "LLM Response: {\n",
      "  \"AnswerType\": \"improper\",\n",
      "  \"Rationale\": \"The user's question is a simple expression of gratitude and does not require a database response. The system response is appropriate and polite, but it is not relevant to the database context. The response is clear, complete, and accurate, but it lacks utility in the context of the database interaction.\",\n",
      "  \"Score\": 6\n",
      "} \n",
      "\n",
      "formatted json {   \"AnswerType\": \"improper\",   \"Rationale\": \"The user's question is a simple expression of gratitude and does not require a database response. The system response is appropriate and polite, but it is not relevant to the database context. The response is clear, complete, and accurate, but it lacks utility in the context of the database interaction.\",   \"Score\": 6 }\n",
      "Next Turn predict_sql: \n",
      "Predict Type: improper\n",
      "__________________\n",
      "0\n",
      "answerable -- What is the average age of the losers from all matches?\n",
      "request gemini-1.5-flash\n",
      "\u001b[92mSuccess: Operation completed after 0 retries\u001b[0m\n",
      "LLM Response: \n",
      "\u001b[91mRQS_eval.py::: Retry Reason: Expecting value: line 1 column 1 (char 0)\u001b[0m\n",
      "request gemini-1.5-flash\n",
      "\u001b[92mSuccess: Operation completed after 0 retries\u001b[0m\n",
      "LLM Response: \n",
      "\u001b[91mRQS_eval.py::: Retry Reason: Expecting value: line 1 column 1 (char 0)\u001b[0m\n",
      "request gemini-1.5-flash\n",
      "\u001b[92mSuccess: Operation completed after 0 retries\u001b[0m\n",
      "LLM Response: \n",
      "\u001b[91mRQS_eval.py::: Retry Reason: Expecting value: line 1 column 1 (char 0)\u001b[0m\n",
      "request gemini-1.5-flash\n",
      "\u001b[92mSuccess: Operation completed after 0 retries\u001b[0m\n",
      "LLM Response: \n",
      "\u001b[91mRQS_eval.py::: Retry Reason: Expecting value: line 1 column 1 (char 0)\u001b[0m\n",
      "request gemini-1.5-flash\n",
      "\u001b[92mSuccess: Operation completed after 0 retries\u001b[0m\n",
      "LLM Response: \n",
      "\u001b[91mRQS_eval.py::: Retry Reason: Expecting value: line 1 column 1 (char 0)\u001b[0m\n",
      "request gemini-1.5-flash\n",
      "\u001b[92mSuccess: Operation completed after 0 retries\u001b[0m\n",
      "LLM Response: \n",
      "\u001b[91mRQS_eval.py::: Retry Reason: Expecting value: line 1 column 1 (char 0)\u001b[0m\n",
      "request gemini-1.5-flash\n",
      "\u001b[92mSuccess: Operation completed after 0 retries\u001b[0m\n",
      "LLM Response: \n",
      "\u001b[91mRQS_eval.py::: Retry Reason: Expecting value: line 1 column 1 (char 0)\u001b[0m\n",
      "request gemini-1.5-flash\n",
      "\u001b[92mSuccess: Operation completed after 0 retries\u001b[0m\n",
      "LLM Response: \n",
      "\u001b[91mRQS_eval.py::: Retry Reason: Expecting value: line 1 column 1 (char 0)\u001b[0m\n",
      "request gemini-1.5-flash\n",
      "\u001b[92mSuccess: Operation completed after 0 retries\u001b[0m\n",
      "LLM Response: \n",
      "\u001b[91mRQS_eval.py::: Retry Reason: Expecting value: line 1 column 1 (char 0)\u001b[0m\n",
      "request gemini-1.5-flash\n",
      "\u001b[92mSuccess: Operation completed after 0 retries\u001b[0m\n",
      "LLM Response: \n",
      "\u001b[91mRQS_eval.py::: Retry Reason: Expecting value: line 1 column 1 (char 0)\u001b[0m\n",
      "Next Turn predict_sql: \n",
      "Predict Type: \u001b[91mFailed to obtain valid response\u001b[0m\n",
      "1\n",
      "answerable -- What about the average age of the winners from all matches?\n",
      "Next Turn predict_sql: SELECT avg(winner_age) FROM matches \n",
      "Predict Type: answerable\n",
      "2\n",
      "answerable -- How many winners are left handed?\n",
      "Next Turn predict_sql: SELECT count(DISTINCT winner_id) FROM matches WHERE winner_hand = 'L'  \n",
      "Predict Type: answerable\n",
      "3\n",
      "answerable -- What are the names of the winner and loser from the longest match?\n",
      "Next Turn predict_sql: SELECT winner_name, loser_name FROM matches ORDER BY minutes DESC LIMIT 1  \n",
      "Predict Type: answerable\n",
      "4\n",
      "improper -- Thanks!\n",
      "request gemini-1.5-flash\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RQS_eval.py\n",
    "\n",
    "Reads a specified JSON file and iterates through each object's 'turns' array to find a turn where 'isuser' is true and its following turn.\n",
    "\n",
    "Usage:\n",
    "    python RQS_eval.py outputs/llm_responses.json outputs/llm_responses_rqs.json\n",
    "\n",
    "Arguments:\n",
    "    --file_path: Path to the JSON file.\n",
    "    --output_path: Path where the modified JSON file will be saved.\n",
    "\"\"\"\n",
    "\n",
    "from tools.api_request import request_gemini as request_llm\n",
    "from tools.db_detail import db_getdesc\n",
    "from tools.sql_execute import sqlite_execute as execute\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def sql_evoke(query,db_name):\n",
    "    result, execution_time ,executable = execute(\"datasets/cosql_dataset/database/\"+db_name+\"/\"+db_name+\".sqlite\",query)\n",
    "    return result \n",
    "\n",
    "def get_example(db_name):\n",
    "    sql_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "    result = sql_evoke(sql_query,db_name)\n",
    "    column_example=\"\"\n",
    "    for table_name in result:\n",
    "        column_example = column_example + table_name[0] + \":\\n\"\n",
    "        sql_get_eg = \"SELECT * FROM \"+ table_name[0] +\" LIMIT 3;\"\n",
    "        table_eg = sql_evoke(sql_get_eg,db_name)\n",
    "        for table_data in table_eg:\n",
    "            column_example = column_example + '('\n",
    "            for column_data in table_data: \n",
    "                column_example = column_example + str(column_data) +','\n",
    "            column_example = column_example[:-1] + ')\\n'\n",
    "    return column_example\n",
    "    \n",
    "\n",
    "def ask_ai(db_name, question, answer_pred, answer_gold):\n",
    "    description = db_getdesc(db_name)\n",
    "    column_example = get_example(db_name)\n",
    "    template = \"\"\"\n",
    "{database_description}\n",
    "\n",
    "{user_question}\n",
    "\n",
    "{system_response}\n",
    "\n",
    "{reference_answer}\n",
    "\n",
    "Evaluate the quality of the system's response based on the following criteria. Assign 2 points directly if a criterion does not apply.\n",
    "Relevance:\n",
    "0 points: The response is completely irrelevant.\n",
    "1 point: The response is partially relevant but misses key details.\n",
    "2 points: The response is fully relevant and addresses the question adequately.\n",
    "Clarity:\n",
    "0 points: The response is incomprehensible.\n",
    "1 point: The response is mostly clear with minor ambiguities.\n",
    "2 points: The response is very clear and easy to understand.\n",
    "Completeness:\n",
    "0 points: The response does not address the question at all.\n",
    "1 point: The response covers most aspects of the question but lacks some details.\n",
    "2 points: The response thoroughly addresses all aspects of the question.\n",
    "Accuracy:\n",
    "0 points: The response contains factually incorrect information.\n",
    "1 point: The response is partially accurate with some errors.\n",
    "2 points: The response is completely accurate.\n",
    "Utility:\n",
    "0 points: The response does not meet the user's needs or explain the context of the question.\n",
    "1 point: The response somewhat meets the user's needs and provides partial explanations.\n",
    "2 points: The response excellently meets the user's needs and clearly explains the context or ambiguity of the question.\n",
    "Task:\n",
    "Classify the Response: Determine if the system response is 'improper'(Non-SQL based user questions), 'unanswerable'(unachievable under existing conditions), or 'ambiguous'(Lack of clarity).\n",
    "Evaluate Each Criterion: Provide a detailed rationale for the score assigned to each criterion.\n",
    "Calculate the Total Score: Sum the scores for all criteria.(10 points for a direct greeting alone)\n",
    "\n",
    "Output Format:\n",
    "{{\n",
    "  \"AnswerType\": \"\",(text only)\n",
    "  \"Rationale\": \"\",(text only)\n",
    "  \"Score\": \"\"(An integer from 0 to 10)\n",
    "}}\n",
    "    \"\"\"\n",
    "    filled_template = template.format(\n",
    "        database_description=\"Database Description:\"+ \"\\nDatabase schema:\\n\" + description + \"\\nExamples for each table:\"+ column_example,\n",
    "        user_question=\"User Question:\" + question,\n",
    "        system_response=\"System Response:\" + answer_pred,\n",
    "        reference_answer=\"Reference Answer:\" + answer_gold\n",
    "    )\n",
    "    \n",
    "    # print(filled_template)\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": filled_template}]\n",
    "    max_attempts = 5\n",
    "    attempt = 0\n",
    "    while attempt < max_attempts:\n",
    "        llm_response = request_llm(messages)\n",
    "        print(\"LLM Response:\", llm_response)\n",
    "        select_pos = llm_response.find('{')\n",
    "        colon_pos = llm_response.find('}', select_pos)\n",
    "        if select_pos != -1 and colon_pos != -1:\n",
    "            llm_response = llm_response[select_pos:colon_pos+1].replace('\\n',' ')\n",
    "            print(\"formatted json \"+llm_response)\n",
    "        try:\n",
    "            response_data = json.loads(llm_response)\n",
    "            type_ai = response_data.get(\"AnswerType\", \"\")\n",
    "            rqs_ai = response_data.get(\"Score\", 0)\n",
    "            rationale_ai = response_data.get(\"Rationale\", \"\")\n",
    "            \n",
    "            # 检查返回的类型和分数是否符合预期\n",
    "            if type_ai in [\"improper\", \"unanswerable\", \"ambiguous\"] and int(rqs_ai) >= 0 and int(rqs_ai) <= 10:\n",
    "                return type_ai, rqs_ai, rationale_ai\n",
    "            else:\n",
    "                raise ValueError(\"Response type or score out of expected range.\")\n",
    "        except (json.JSONDecodeError, KeyError, ValueError, TypeError, Exception) as e:\n",
    "            print(\"\\033[91mRQS_eval.py::: Retry Reason: {}\\033[0m\".format(str(e)))  # 红色字体提示重试原因\n",
    "            attempt += 1\n",
    "    return \"error\", 0, \"error\"\n",
    "\n",
    "def process_turns(file_path, output_path):\n",
    "\n",
    "    # Open and read the JSON file\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Iterate over each object in the file\n",
    "    for entry in tqdm(data):\n",
    "        # Check if the 'turns' key exists\n",
    "        print(\"__________________\")\n",
    "        if 'turns' in entry:\n",
    "            turns = entry['turns']\n",
    "            db_name = entry['db_name']\n",
    "            length = len(turns)\n",
    "            # Iterate over each turn in 'turns'\n",
    "            for i in range(length):\n",
    "                # Check if the current turn is a user turn\n",
    "                if turns[i].get('isuser', False):\n",
    "                    print(i//2)\n",
    "                    # Output the current user's turn\n",
    "                    print(turns[i].get('type', ''), \"--\", turns[i].get('text', ''))\n",
    "                    # Check and process the next turn (if it exists)\n",
    "                    if i + 1 < length:\n",
    "                        next_turn = turns[i + 1]\n",
    "                        predict_text = next_turn.get('predict', '')\n",
    "                        # Find the positions of SELECT and the semicolon\n",
    "                        select_pos = predict_text.upper().find('SELECT')\n",
    "                        colon_pos = predict_text.find(';', select_pos)\n",
    "                        if select_pos != -1 and colon_pos != -1:\n",
    "                            predict_sql = predict_text[select_pos:colon_pos].replace('\\n',' ')\n",
    "                        elif select_pos != -1:\n",
    "                            predict_sql = predict_text[select_pos:].replace('\\n',' ')\n",
    "                        else:\n",
    "                            predict_sql = \"\"\n",
    "                        # Store the result in a new field 'predict_sql'\n",
    "                        next_turn['predict_sql'] = predict_sql\n",
    "                        # Calculate the ratio of the extracted SQL to the entire predict field\n",
    "                        if len(predict_text) == 0:\n",
    "                            ratio = 0\n",
    "                        else:\n",
    "                            ratio = len(predict_sql) / len(predict_text)\n",
    "                            \n",
    "                        if predict_sql != \"\" and ratio >= 0.5:\n",
    "                                next_turn['predict_type'] = 'answerable'\n",
    "                                if turns[i].get('type', '') == 'answerable':\n",
    "                                    next_turn['RQS'] = \"N/A\"\n",
    "                                else:\n",
    "                                    next_turn['RQS'] = 0\n",
    "                        else:\n",
    "                            next_turn['predict_type'] = 'not answerable'\n",
    "                            # Ask LLM, Get categorized and RQS scored based on database, questions, answers, gold answer\n",
    "                            type_ai, rqs_ai, rationale_ai = ask_ai(db_name,turns[i].get('text', ''),predict_text,next_turn.get('text', '')) \n",
    "                            next_turn['predict_type'] = type_ai\n",
    "                            next_turn['RQS'] = rqs_ai\n",
    "                            next_turn['RQS_Rationale'] = rationale_ai\n",
    "                        print(\"Next Turn predict_sql:\", predict_sql)\n",
    "                        print(\"Predict Type:\", next_turn['predict_type'])\n",
    "                    else:\n",
    "                        print(\"Next Turn does not exist.\")\n",
    "    \n",
    "    # Save the modified data to a new JSON file\n",
    "    with open(output_path, 'w') as outfile:\n",
    "        json.dump(data, outfile, indent=4)\n",
    "\n",
    "# Example usage\n",
    "input_file_path = 'outputs/gemini-1-Copy1.5-flash-llm.json'\n",
    "output_file_path = 'outputs/rqs_gemini-1-Copy1.5-flash-llm.json.json'\n",
    "process_turns(input_file_path, output_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
