{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ff1b2ab-49df-44b4-b00c-d7b9dbff90f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished1\n",
      "finished2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2458/2458 [00:00<00:00, 102426.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_dialog_info1(json_file, output_file):\n",
    "    \"\"\"\n",
    "    从 JSON 文件中提取对话信息，并保存到新的 JSON 文件\n",
    "\n",
    "    Args:\n",
    "        json_file: 输入 JSON 文件路径\n",
    "        output_file: 输出 JSON 文件路径\n",
    "    \"\"\"\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    new_data = []\n",
    "    for index, dialog in enumerate(data.values()):\n",
    "        new_dialog = {\n",
    "            \"goal_question\": \"originCosql\",\n",
    "            \"evidence\": \"nan\",\n",
    "            \"db_name\": dialog.get(\"db_id\", \"N/A\"),\n",
    "            \"turns\": [\n",
    "                {\n",
    "                    \"isuser\": turn[\"isUser\"],\n",
    "                    \"text\": turn[\"text\"],\n",
    "                    \"type\": turn.get(\"label\",\"\"), \n",
    "                    \"query\": turn.get(\"rawSql\",\"\")\n",
    "                }\n",
    "                for index, turn in enumerate(dialog[\"turns\"])\n",
    "            ]\n",
    "        }\n",
    "        new_data.append(new_dialog)\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(new_data, f, indent=4)\n",
    "\n",
    "# 示例用法\n",
    "input_file = \"cosql_all_info_dialogs.json\"\n",
    "output_file = \"extracted_data.json\"\n",
    "extract_dialog_info1(input_file, output_file)\n",
    "\n",
    "print(\"finished1\")\n",
    "\n",
    "def extract_dialog_info2(json_file, output_file):\n",
    "    \"\"\"\n",
    "    从 JSON 文件中提取对话信息，并保存到新的 JSON 文件\n",
    "\n",
    "    Args:\n",
    "        json_file: 输入 JSON 文件路径\n",
    "        output_file: 输出 JSON 文件路径\n",
    "    \"\"\"\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    new_data = []\n",
    "    for dialog in data:\n",
    "        new_dialog = {\n",
    "            \"goal_question\": \"originCosql\",\n",
    "            \"evidence\": \"nan\",\n",
    "            \"db_name\": dialog.get(\"db_name\", \"N/A\"),\n",
    "            \"turns\": []\n",
    "        }\n",
    "\n",
    "        for i, turn in enumerate(dialog[\"turns\"]):\n",
    "            if turn[\"isuser\"]:\n",
    "                value = turn.get(\"type\", \"\")\n",
    "                first_char = value[0] if value else \"\"\n",
    "                new_turn = {\n",
    "                    \"isuser\": turn[\"isuser\"],\n",
    "                    \"text\": turn[\"text\"],\n",
    "                    \"type\": first_char\n",
    "                }\n",
    "                new_dialog[\"turns\"].append(new_turn)\n",
    "            else:\n",
    "                if i > 0 and dialog[\"turns\"][i-1][\"isuser\"]:\n",
    "                    if i + 1 < len(dialog[\"turns\"]):\n",
    "                        text = dialog[\"turns\"][i+1].get(\"text\",\"\")\n",
    "                    else:\n",
    "                        text = turn[\"text\"]\n",
    "                    new_turn = {\n",
    "                    \"isuser\": turn[\"isuser\"],\n",
    "                    \"text\": text,\n",
    "                    \"query\": turn.get(\"query\", \"\")\n",
    "                    }\n",
    "                    new_dialog[\"turns\"].append(new_turn)\n",
    "                else:\n",
    "                    # 处理异常情况，例如连续多个 isUser: false\n",
    "                    pass\n",
    "\n",
    "        new_data.append(new_dialog)\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(new_data, f, indent=4)\n",
    "\n",
    "# 示例用法\n",
    "input_file = \"extracted_data.json\"\n",
    "output_file = \"extracted_data.json\"\n",
    "extract_dialog_info2(input_file, output_file)\n",
    "print(\"finished2\")\n",
    "\n",
    "def filter_by_average_length(data, output_file):\n",
    "    \"\"\"\n",
    "    筛选平均文本长度大于指定阈值的问答对\n",
    "\n",
    "    Args:\n",
    "        data: 原始 JSON 数据\n",
    "        threshold: 平均文本长度阈值\n",
    "\n",
    "    Returns:\n",
    "        list: 符合条件的问答对列表\n",
    "    \"\"\"\n",
    "    with open(data, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for dialog in tqdm(data):\n",
    "        system_responses = [turn['text'] for turn in dialog['turns'] if not turn['isuser']]\n",
    "\n",
    "        # 使用 split() 计算单词数\n",
    "        total_words = sum(len(text.split()) for text in system_responses)\n",
    "        avg_word_count = total_words / len(system_responses) if system_responses else 0\n",
    "\n",
    "        if avg_word_count >= 11.5:\n",
    "            results.append(dialog)\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    return results\n",
    "\n",
    "input_file = \"extracted_data.json\"\n",
    "output_file = \"extracted_data.json\"\n",
    "filter_by_average_length(input_file, output_file)\n",
    "\n",
    "print(\"finished3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d7ed4f7-94fe-4132-8a35-acef0f1e199f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def merge_json_files(file1, file2, output_file):\n",
    "    \"\"\"合并两个 JSON 文件。\n",
    "\n",
    "    Args:\n",
    "        file1: 第一个 JSON 文件路径。\n",
    "        file2: 第二个 JSON 文件路径。\n",
    "        output_file: 输出文件路径。\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file1, 'r') as f:\n",
    "        data1 = json.load(f)\n",
    "\n",
    "    with open(file2, 'r') as f:\n",
    "        data2 = json.load(f)\n",
    "\n",
    "    # 这里根据实际情况选择合并方式\n",
    "    combined_data = data1 + data2  # 示例：合并列表\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(combined_data, f, indent=4)\n",
    "\n",
    "# 调用函数\n",
    "merge_json_files('extracted_data.json', '全部增强数据.json', 'combined_data.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5d00670-8614-4682-8208-0c1b7d7eb57c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 11553/11553 [00:00<00:00, 65332.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished4\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def filter_by_average_length(data, output_file):\n",
    "    \"\"\"\n",
    "    筛选平均文本长度大于指定阈值的问答对\n",
    "\n",
    "    Args:\n",
    "        data: 原始 JSON 数据\n",
    "        threshold: 平均文本长度阈值\n",
    "\n",
    "    Returns:\n",
    "        list: 符合条件的问答对列表\n",
    "    \"\"\"\n",
    "    with open(data, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for dialog in tqdm(data):\n",
    "        system_responses = [turn['text'] for turn in dialog['turns'] if not turn.get('isuser',\"\")==True]\n",
    "        \n",
    "        # 使用 split() 计算单词数\n",
    "        total_words = sum(len(text.split()) for text in system_responses)\n",
    "        avg_word_count = total_words / len(system_responses) if system_responses else 0\n",
    "\n",
    "        if avg_word_count > 15:\n",
    "            results.append(dialog)\n",
    "        elif avg_word_count >= 5:\n",
    "            # 如果平均单词数大于等于12且小于13，则随机决定是否保留\n",
    "            if random.random() < 0.5:  # 随机生成0到1之间的数，小于0.5则保留\n",
    "                results.append(dialog)\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    return results\n",
    "\n",
    "input_file = \"combined_data.json\"\n",
    "output_file = \"combined_data1.json\"\n",
    "filter_by_average_length(input_file, output_file)\n",
    "\n",
    "print(\"finished4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "682476ca-fa1e-47dd-9def-72b4d2391846",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def classify_type(old_type):\n",
    "    \"\"\"\n",
    "    根据旧的 type 值，返回新的分类。\n",
    "\n",
    "    Args:\n",
    "        old_type: 旧的 type 值。\n",
    "\n",
    "    Returns:\n",
    "        新的 type 值。\n",
    "    \"\"\"\n",
    "\n",
    "    type_mapping = {\n",
    "        'INFORM_SQL': 'answerable',\n",
    "        'INFER_SQL AFFIRM': 'answerable',\n",
    "        'AMBIGUOUS': 'ambiguous',\n",
    "        'CANNOT_ANSWER': 'unanswerable',\n",
    "        'CANNOT_UNDERSTAND': 'unanswerable',\n",
    "        'NOT_RELATED': 'unanswerable',\n",
    "    }\n",
    "    \n",
    "    # print(old_type,type_mapping.get(old_type, 'improper'))\n",
    "    \n",
    "    return type_mapping.get(old_type, 'improper')\n",
    "\n",
    "def filter_turns(data_file, output_file):\n",
    "    \"\"\"\n",
    "    过滤 turns 中的字段。\n",
    "\n",
    "    Args:\n",
    "        data_file: 输入 JSON 文件路径。\n",
    "        output_file: 输出 JSON 文件路径。\n",
    "    \"\"\"\n",
    "\n",
    "    with open(data_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    for dialog in data:\n",
    "        for i, turn in enumerate(dialog['turns']):\n",
    "            if turn['isuser']:\n",
    "                # 用户提问，保留 text 和 type\n",
    "                dialog['turns'][i] = {'isuser':True, 'text': turn['text'], 'type': classify_type(turn['type'])}\n",
    "            else:\n",
    "                # 系统回答，保留 text 和 query\n",
    "                dialog['turns'][i] = {'isuser':False, 'text': turn['text'], 'query': turn.get('query', \"\")}\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "\n",
    "# 示例用法\n",
    "filter_turns('combined_data1.json', 'combined_data2.json')\n",
    "print(\"finished5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29622adc-3e04-49c3-bd3b-21237573cf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total turns: 6493\n",
      "Q&A: 38666\n",
      "Q&A/Turns: 5.96\n",
      "Average question length: 11.42 words\n"
     ]
    }
   ],
   "source": [
    "# Count statistics for the dataset\n",
    "import json\n",
    "\n",
    "with open('datasets/MMSQL_train.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize counters\n",
    "total_turns = 0\n",
    "user_turns = 0\n",
    "total_user_text_length = 0\n",
    "\n",
    "# Traverse the dataset\n",
    "for item in data:\n",
    "    total_turns += 1\n",
    "    for turn in item['turns']:\n",
    "        if turn['isuser']:\n",
    "            user_turns += 1\n",
    "            total_user_text_length += len(turn['text'].split())\n",
    "\n",
    "# Calculate average question length\n",
    "average_question_length = total_user_text_length / user_turns if user_turns else 0\n",
    "\n",
    "print(f\"Total turns: {total_turns}\")\n",
    "print(f\"Q&A: {user_turns}\")\n",
    "print(f\"Q&A/Turns: {(user_turns/total_turns):.2f}\")\n",
    "print(f\"Average question length: {average_question_length:.2f} words\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
